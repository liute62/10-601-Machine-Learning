# Notes of CMU-10-601 Machine Learning Class

## k-Nearest Neighbors

## MLE & MAP

## Naive Bayes

## Linear Regression

## Logic Regression

## Regularization

## Perceptron

## Kernels

## SVM

## k-Means

### Algorithm

### Initialization

## EM & Gaussian Mixture Model

                          Table.1 Relationship between GNB, GDA and GMM

|          |Guassian Naive Bayes | Guassian Discriminative Analysis| Guassian Mixture Model |
|:-------- |:------------------- | :-------------------------------- | :------------------- |
| Data   | options             | object                           | Small preset options |
| Model  | options             | object                            | Small preset option  |
| Decision Rule  | options             | object                            | Small preset option  |
| Objective Function  | options             | object                            | Small preset option  |
| Optimization Method | options             | object                            | Small preset option  |

### Expectation Maximization

#### Calculation Formula

#### A report Card for EM

#### Good Things

#### Bad Things

     Table.2 Comparision Between EM for GMM and EM for k-means

|          |EM for Guassian Mixture Model           | EM for K-means |
|:-------- |:------------------- | :-------------------------------- |
| Data   | options             | object                             | 
| Model  | options             | object                            |

## PCA

## Nerual Network & CNN

### Back Propagation

## Bayes Network

### Evaluate Params

### Conditional Dependency Analysis

## Hidden Markov Model

### Forward Algorithm

### Backward Algorithm

## Matrix Factorization

### Alternating Least Square Error

## Learning Theory

### PAC Theory
